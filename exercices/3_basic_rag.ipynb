{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ggtxTsKP96C"
      },
      "source": [
        "## Building a Retrieval-Augmented Generation (RAG) System with LangChain\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this notebook, we will learn how to build a Retrieval-Augmented Generation (RAG) system using LangChain in Python. RAG systems combine information retrieval and natural language generation to produce answers that are grounded in external knowledge bases. This approach is particularly useful when dealing with large documents or datasets where direct querying isn’t efficient or possible.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "- Understand the concept of Retrieval-Augmented Generation (RAG).\n",
        "- Learn how to use LangChain to implement a RAG system.\n",
        "- Implement the system step by step with guided TODO tasks.\n",
        "- Test your implementation at each step.\n",
        "- Provide helpful explanations and definitions.\n",
        "\n",
        "Help\n",
        "\n",
        "### Methods Used:\n",
        "\n",
        "- LangChain: A library for building language model applications.\n",
        "- VectorStore (FAISS): A tool for efficient similarity search and clustering of dense vectors.\n",
        "- OpenAI Embeddings: Representations of text that can capture semantic meaning.\n",
        "- RetrievalQA Chain: Combines retrieval and question-answering over documents.\n",
        "\n",
        "### Data Used\n",
        "\n",
        "- I extracted some chapters of the Gen AI course as a txt file.\n",
        "- The goal how this notebook is to build a RAG system that can answer questions based on the content of these chapters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wch8dLFP96G"
      },
      "source": [
        "## Step 1: Set Up Your Environment\n",
        "\n",
        "We need to import the required modules and set up the OpenAI API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TReBlsHjP96H",
        "outputId": "d798d8b1-3c59-4b18-fb68-b9a71f56c09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQr_XEQoP96J",
        "outputId": "59d933ce-f42b-4039-a0d3-5bbeb46e0bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_openai\n",
            "  Using cached langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.12 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain_openai) (0.3.13)\n",
            "Collecting openai<2.0.0,>=1.52.0 (from langchain_openai)\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (0.1.137)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (9.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.12->langchain_openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.6.2.post1)\n",
            "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.52.0->langchain_openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (0.27.2)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.52.0->langchain_openai)\n",
            "  Using cached jiter-0.6.1-cp312-none-win_amd64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: sniffio in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from openai<2.0.0,>=1.52.0->langchain_openai) (4.66.5)\n",
            "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
            "  Using cached regex-2024.9.11-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.52.0->langchain_openai) (3.10)\n",
            "Requirement already satisfied: certifi in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.52.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain_openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.12->langchain_openai) (3.10.10)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.12->langchain_openai) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.12->langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.12->langchain_openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.52.0->langchain_openai) (0.4.6)\n",
            "Using cached langchain_openai-0.2.3-py3-none-any.whl (49 kB)\n",
            "Downloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "Using cached tiktoken-0.8.0-cp312-cp312-win_amd64.whl (883 kB)\n",
            "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Using cached jiter-0.6.1-cp312-none-win_amd64.whl (198 kB)\n",
            "Using cached regex-2024.9.11-cp312-cp312-win_amd64.whl (273 kB)\n",
            "Installing collected packages: regex, jiter, distro, tiktoken, openai, langchain_openai\n",
            "Successfully installed distro-1.9.0 jiter-0.6.1 langchain_openai-0.2.3 openai-1.52.2 regex-2024.9.11 tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_lhKp7FP96J"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from langchain import OpenAI, hub\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.documents.base import Document # type: ignore\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from typing import List\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3gUI1ykP96K"
      },
      "outputs": [],
      "source": [
        "load_dotenv()\n",
        "sys.path.append(\"../\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nn4ww47gP96L"
      },
      "source": [
        "## Step 2: Load and Split Documents\n",
        "\n",
        "Load the document you want to use and split it into manageable chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNirokaIP96M"
      },
      "outputs": [],
      "source": [
        "# TODO: Load your document and split it into chunks\n",
        "# Hint: Use TextLoader and RecursiveCharacterTextSplitter\n",
        "\n",
        "filename = \"gen_ai_course.txt\"\n",
        "# Answer:\n",
        "loader = TextLoader(filename,encoding=\"utf8\")\n",
        "documents = loader.load()\n",
        "\n",
        "# Answer\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQKvHHxAP96N"
      },
      "source": [
        "## Step 3: Create Embeddings and Build the VectorStore\n",
        "\n",
        "Generate embeddings for each chunk and store them in a vector store for efficient retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMTADyQvP96N",
        "outputId": "a13adfdd-1338-47f1-a9a7-04046b19ee6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIzaSyA0BJ-l4g5TYK-Gd0fvK6lJMUIroDsr1rI\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.environ[\"AIzaSyA0BJ-l4g5TYK-Gd0fvK6lJMUIroDsr1rI\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmYG80YAP96O",
        "outputId": "54a5455d-be15-4517-97d8-c14c95d3208b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpuNote: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\gaming\\genai-dauphine-course\\genai\\lib\\site-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp312-cp312-win_amd64.whl (13.8 MB)\n",
            "   ---------------------------------------- 0.0/13.8 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/13.8 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/13.8 MB 2.4 MB/s eta 0:00:06\n",
            "   --- ------------------------------------ 1.3/13.8 MB 2.8 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 2.1/13.8 MB 3.0 MB/s eta 0:00:04\n",
            "   ------- -------------------------------- 2.6/13.8 MB 3.1 MB/s eta 0:00:04\n",
            "   -------- ------------------------------- 2.9/13.8 MB 2.5 MB/s eta 0:00:05\n",
            "   --------- ------------------------------ 3.4/13.8 MB 2.6 MB/s eta 0:00:05\n",
            "   ----------- ---------------------------- 3.9/13.8 MB 2.6 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 4.2/13.8 MB 2.5 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 4.7/13.8 MB 2.5 MB/s eta 0:00:04\n",
            "   -------------- ------------------------- 5.0/13.8 MB 2.5 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 5.5/13.8 MB 2.3 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 5.8/13.8 MB 2.2 MB/s eta 0:00:04\n",
            "   ----------------- ---------------------- 6.0/13.8 MB 2.2 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 6.3/13.8 MB 2.1 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 6.6/13.8 MB 2.1 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 6.8/13.8 MB 2.0 MB/s eta 0:00:04\n",
            "   -------------------- ------------------- 7.1/13.8 MB 2.0 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 7.3/13.8 MB 1.9 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 7.6/13.8 MB 1.9 MB/s eta 0:00:04\n",
            "   ---------------------- ----------------- 7.9/13.8 MB 1.9 MB/s eta 0:00:04\n",
            "   ----------------------- ---------------- 8.1/13.8 MB 1.9 MB/s eta 0:00:04\n",
            "   ------------------------ --------------- 8.4/13.8 MB 1.8 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 8.7/13.8 MB 1.8 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 8.9/13.8 MB 1.8 MB/s eta 0:00:03\n",
            "   -------------------------- ------------- 9.2/13.8 MB 1.8 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 9.7/13.8 MB 1.7 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 10.0/13.8 MB 1.7 MB/s eta 0:00:03\n",
            "   ------------------------------ --------- 10.5/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 10.7/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 11.0/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 11.3/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 11.5/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 11.8/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 12.1/13.8 MB 1.7 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 12.3/13.8 MB 1.7 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 12.6/13.8 MB 1.7 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 13.1/13.8 MB 1.7 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 13.4/13.8 MB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------  13.6/13.8 MB 1.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 13.8/13.8 MB 1.6 MB/s eta 0:00:00\n",
            "Installing collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ],
      "source": [
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7T8hwFBBP96O"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "\n",
        "\n",
        "import faiss\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "vectorstore = FAISS.from_documents(documents=docs, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpZNLmzFP96P",
        "outputId": "1e2b88c2-32c3-4090-b151-4c6cb3010686"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\GAMING\\GenAI-Dauphine-Course\\GenAI\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:55\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: Create embeddings and store them in a VectorStore\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Hint: Use OpenAIEmbeddings and FAISS\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m  \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\GAMING\\GenAI-Dauphine-Course\\GenAI\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:852\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    850\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 852\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\GAMING\\GenAI-Dauphine-Course\\GenAI\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1042\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1024\u001b[0m \n\u001b[0;32m   1025\u001b[0m \u001b[38;5;124;03mThis is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m        faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[1;32m-> 1042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\GAMING\\GenAI-Dauphine-Course\\GenAI\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:994\u001b[0m, in \u001b[0;36mFAISS.__from\u001b[1;34m(cls, texts, embeddings, embedding, metadatas, ids, normalize_L2, distance_strategy, **kwargs)\u001b[0m\n\u001b[0;32m    982\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__from\u001b[39m(\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    993\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[1;32m--> 994\u001b[0m     faiss \u001b[38;5;241m=\u001b[39m \u001b[43mdependable_faiss_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m distance_strategy \u001b[38;5;241m==\u001b[39m DistanceStrategy\u001b[38;5;241m.\u001b[39mMAX_INNER_PRODUCT:\n\u001b[0;32m    996\u001b[0m         index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatIP(\u001b[38;5;28mlen\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m]))\n",
            "File \u001b[1;32mc:\\Users\\GAMING\\GenAI-Dauphine-Course\\GenAI\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:57\u001b[0m, in \u001b[0;36mdependable_faiss_import\u001b[1;34m(no_avx2)\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import faiss python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install faiss-gpu` (for CUDA supported GPU) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `pip install faiss-cpu` (depending on Python version).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m     )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m faiss\n",
            "\u001b[1;31mImportError\u001b[0m: Could not import faiss python package. Please install it with `pip install faiss-gpu` (for CUDA supported GPU) or `pip install faiss-cpu` (depending on Python version)."
          ]
        }
      ],
      "source": [
        "# TODO: Create embeddings and store them in a VectorStore\n",
        "# Hint: Use OpenAIEmbeddings and FAISS\n",
        "\n",
        "vectorstore =  FAISS.from_documents(documents=docs, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tg7A1X6P96Q"
      },
      "source": [
        "## Step 4: Set Up the QA Chain using LCEL\n",
        "\n",
        "Create a chain that can retrieve relevant chunks and generate answers based on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8ULyy0jP96R",
        "outputId": "5fb50c72-db79-4cbb-fe5f-e9e60b141be9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What's a Retrieval Augmented Generation?\n",
            "Answer: Retrieval Augmented Generation (RAG) combines retrieval-based and generation-based models.  It enhances language models by giving them access to external knowledge bases or documents during generation. This allows the model to generate more accurate, up-to-date information by retrieving relevant data, reducing hallucinations common in standard language models.  Instead of relying solely on information learned during training, RAG models can access and use new information, making them more adaptable and factual.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-pro\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are a question answering chatbot.\n",
        "            You'll say if you don't know.\n",
        "            You'll find the relevant information in {formatted_docs}.\n",
        "            Answer in at most 5 sentences.\"\"\",\n",
        "        ),\n",
        "        (\"human\", \"{query}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "def format_docs(docs: List[Document]):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "question = \"What's a Retrieval Augmented Generation?\"\n",
        "\n",
        "\n",
        "formatted_docs = format_docs(docs)\n",
        "\n",
        "# Answer:\n",
        "qa_chain = prompt | llm\n",
        "answer = qa_chain.invoke(\n",
        "    {\n",
        "        \"input_language\": \"English\" or \"French\",\n",
        "        \"output_language\": \"English\",\n",
        "        \"query\": question,\n",
        "        \"formatted_docs\": formatted_docs,\n",
        "    }\n",
        ").content\n",
        "\n",
        "print(f\"Question: {question}\\nAnswer: {answer}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytDp9mdfP96R"
      },
      "source": [
        "## Step 5: Ask Questions and Get Answers\n",
        "\n",
        "Test the system by asking a question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnEqtcZpP96S",
        "outputId": "0f0650b6-a8d0-4499-8a1d-2d42c64d1c90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: What is a transformer?\n",
            "Answer: Transformers are a type of neural network architecture primarily used in natural language processing.  They rely on a mechanism called self-attention, which allows the model to weigh the importance of different parts of the input data when processing it. Unlike recurrent neural networks, transformers process data in parallel, making them more computationally efficient.  They have achieved state-of-the-art results in various NLP tasks, including machine translation and text generation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TODO: Ask a question to the QA chain\n",
        "# Replace 'Your question here' with an actual question and run the qa_chain for this question\n",
        "\n",
        "# Answer:\n",
        "query = \"What is a transformer?\"\n",
        "result = qa_chain.invoke(\n",
        "    {\n",
        "        \"query\": query,\n",
        "        \"formatted_docs\": formatted_docs,\n",
        "    }).content\n",
        "print(f\"Question: {query}\\nAnswer: {result}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF25amJTP96S"
      },
      "source": [
        "## Step 6: Test Your Implementation with Different Questions\n",
        "\n",
        "Try out different questions to see how the system performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Ga-NeBP96S"
      },
      "outputs": [],
      "source": [
        "# Replace 'Another question here' with your own question and run the qa_chain for this question\n",
        "\n",
        "query = \"Can you summarize the key points mentioned?\"\n",
        "result = ...\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IeBmjx7P96S"
      },
      "source": [
        "## Step 7: Improve the System\n",
        "\n",
        "You can experiment with different parameters, like adjusting the chunk size or using a different language model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZSvZZ87P96S"
      },
      "source": [
        "Conclusion\n",
        "\n",
        "Congratulations! You’ve built a simple Retrieval-Augmented Generation system using LangChain. This system can retrieve relevant information from documents and generate answers to user queries.\n",
        "\n",
        "Help\n",
        "\n",
        "- TextLoader: Loads text data from files.\n",
        "- RecursiveCharacterTextSplitter: Splits text into smaller chunks for better processing.\n",
        "- FAISS: A library for efficient similarity search of embeddings.\n",
        "- RetrievalQA Chain: A chain that retrieves relevant documents and answers questions based on them.\n",
        "- OpenAIEmbeddings: Generates embeddings that capture the semantic meaning of text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KePy1okNP96S"
      },
      "source": [
        "## Help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9QcGy1dP96T"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template = ChatPromptTemplate([\n",
        "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
        "    (\"human\", \"Hello, how are you doing?\"),\n",
        "    (\"ai\", \"I'm doing well, thanks!\"),\n",
        "    (\"human\", \"{user_input}\"),\n",
        "])\n",
        "\n",
        "prompt_value = template.invoke(\n",
        "    {\n",
        "        \"name\": \"Bob\",\n",
        "        \"user_input\": \"What is your name?\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Output:\n",
        "# ChatPromptValue(\n",
        "#    messages=[\n",
        "#        SystemMessage(content='You are a helpful AI bot. Your name is Bob.'),\n",
        "#        HumanMessage(content='Hello, how are you doing?'),\n",
        "#        AIMessage(content=\"I'm doing well, thanks!\"),\n",
        "#        HumanMessage(content='What is your name?')\n",
        "#    ]\n",
        "#)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "GenAI",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
